@inproceedings{NACCLacronym,
	author =       {Hu, Hai},
	title =        {Is {China} entering {WTO} or shijie maoyi zuzhi--A Corpus-based Study of {English} Acronyms in {Chinese} Newspapers},
	booktitle =    "Proceedings of 28th North America Conference on Chinese Linguistics",
	year =         "2016",
	url_Paper={https://arxiv.org/abs/1711.06895},
	
}

@inproceedings{NACCL2017chengduvowel,
	author =       {Hu, Hai and Zhang, Yiwen},
	title =        {Path of Vowel Raising in {Chengdu} Dialect of {Mandarin}},
	booktitle =    "Proceedings of 29th North America Conference on Chinese Linguistics",
	year =         "2017",
	pages={481--498},
	url_Paper = {https://arxiv.org/pdf/1803.03887.pdf},
}

@inproceedings{LFG,
	author =       {Damir Cavar and Lwin Moe and Hai Hu and Kenneth Steimel},
	title =        {Preliminary Results from the {Free Linguistic Environment} Project},
	booktitle =    "Joint 2016 Conference on Head-driven Phrase Structure Grammar and Lexical Functional Grammar (HeadLex 2016)",
	year =         "2016",
	pages={161--181},
	url_Paper = { http://nlp.ipipan.waw.pl/HeadLex16/cavar_etal.pdf},
}

@inproceedings{hu-etal-2017-non,
    title = "Non-Deterministic Segmentation for {C}hinese Lattice Parsing",
    author = {Hu, Hai  and
      Dakota, Daniel  and
      K{\"u}bler, Sandra},
    booktitle = "Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",
    month = sep,
    year = "2017",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url_Paper = "https://doi.org/10.26615/978-954-452-049-6_043",
    doi = "10.26615/978-954-452-049-6_043",
    pages = "316--324",
    abstract = "Parsing Chinese critically depends on correct word segmentation for the parser since incorrect segmentation inevitably causes incorrect parses. We investigate a pipeline approach to segmentation and parsing using word lattices as parser input. We compare CRF-based and lexicon-based approaches to word segmentation. Our results show that the lattice parser is capable of selecting the correction segmentation from thousands of options, thus drastically reducing the number of unparsed sentence. Lexicon-based parsing models have a better coverage than the CRF-based approach, but the many options are more difficult to handle. We reach our best result by using a lexicon from the n-best CRF analyses, combined with highly probable words.",
}

@inproceedings{NLCS2018,
	author={Hu, Hai and Icard, Thomas and Moss, Larry},
	title={Automated Reasoning from Polarized Parse Trees},
	booktitle={Proceedings of the Fifth Workshop on Natural Language and Computer Science (NLCS), 2018},
	year={2018},
	url_Paper={https://easychair.org/publications/preprint/xJmn}
}

@inproceedings{hu-moss-2018-polarity,
    title = "Polarity Computations in Flexible Categorial Grammar",
    author = "Hu, Hai  and
      Moss, Larry",
    booktitle = "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url_Paper = "https://www.aclweb.org/anthology/S18-2015",
    doi = "10.18653/v1/S18-2015",
    pages = "124--129",
    abstract = "This paper shows how to take parse trees in CCG and algorithmically find the polarities of all the constituents. Our work uses the well-known polarization principle corresponding to function application, and we have extended this with principles for type raising and composition. We provide an algorithm, extending the polarity marking algorithm of van Benthem. We discuss how our system works in practice, taking input from the C{\&}C parser.",
}





